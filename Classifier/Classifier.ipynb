{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2\n",
    "\n",
    "#### Machine Learning in Korea University\n",
    "#### COSE362, Fall 2018\n",
    "#### Due : 11/26 (TUE) 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, you will learn various classification methods with given datasets.\n",
    "* Implementation detail: Anaconda 5.3 with python 3.7\n",
    "* Use given dataset. Please do not change train / valid / test split.\n",
    "* Use numpy, scikit-learn, and matplotlib library\n",
    "* You don't have to use all imported packages below. (some are optional). <br>\n",
    "Also, you can import additional packages in \"(Option) Other Classifiers\" part. \n",
    "* <b>*DO NOT MODIFY OTHER PARTS OF CODES EXCEPT \"Your Code Here\"*</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Additional packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your own packages if you need(only in scikit-learn, numpy, pandas).\n",
    "# Your Code Here\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "#End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "> 1. Load \"train.csv\". It includes all samples' features and labels.\n",
    "> 2. Training four types of classifiers(logistic regression, decision tree, random forest, support vector machine) and <b>validate</b> it in your own way. <b>(You can't get full credit if you don't conduct validation)</b>\n",
    "> 3. Optionally, if you would train your own classifier(e.g. ensembling or gradient boosting), you can evaluate your own model on the development data. <br>\n",
    "> 4. <b>You should submit your predicted results on test data with the selected classifier in your own manner.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task & dataset description\n",
    "1. 6 Features (1~6)<br>\n",
    "Feature 2, 4, 6 : Real-valued<br>\n",
    "Feature 1, 3, 5 : Categorical <br>\n",
    "\n",
    "2. Samples <br>\n",
    ">In development set : 2,000 samples <br>\n",
    ">In test set : 1,500 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load development dataset\n",
    "Load your development dataset. You should read <b>\"train.csv\"</b>. This is a classification task, and you need to preprocess your data for training your model. <br>\n",
    "> You need to use <b>1-of-K coding scheme</b>, to convert categorical features to one-hot vector. <br>\n",
    "> For example, if there are 3 categorical values, you can convert these features as [1,0,0], [0,1,0], [0,0,1] by 1-of-K coding scheme. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training your model, you need to convert categorical features to one-hot encoding vectors.\n",
    "# Your Code Here\n",
    "\n",
    "# define datasets, dictionaries and functions\n",
    "lab = LabelEncoder()\n",
    "train_data = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "oneHot = OneHotEncoder()\n",
    "train_values = train_data.reset_index().values\n",
    "real_features = [1,3,5]\n",
    "categorical_features = [0,2,4]\n",
    "y_feature = 6\n",
    "train_X = np.asarray(train_values)\n",
    "train_y = train_values[:,y_feature]\n",
    "        \n",
    "# implement OneHotEncoding\n",
    "for val in categorical_features:\n",
    "    feature = train_values[:,val]\n",
    "    feature = oneHot.fit_transform(feature.reshape(-1,1)).toarray()\n",
    "    train_X = np.concatenate((train_X, feature), axis = 1)\n",
    "# end OneHotEncoding\n",
    "\n",
    "# implement delete categorical datas and refine training y data\n",
    "train_X = np.delete(train_X, y_feature, 1)\n",
    "train_X = np.delete(train_X, categorical_features, 1)\n",
    "train_y = lab.fit_transform(train_y)\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Train and validate your <b>logistic regression classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 Score : 0.0919567249003688\n",
      "Maximum F1 Score : 0.1180261421293383\n",
      "Maximum F1 Score : 0.12662711493342677\n",
      "Maximum F1 Score : 0.22242448506829962\n",
      "Maximum F1 Score : 0.2306920358937387\n",
      "Maximum F1 Score : 0.266012118149771\n",
      "My LogisticRegression's f1 score : 0.42419501862709197\n"
     ]
    }
   ],
   "source": [
    "# Training your logistic regression classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#define variables\n",
    "opt_LogReg = LogisticRegression()\n",
    "coefs = [0.01, 0.05, 0.1, 0.5, 1, 10]\n",
    "max_cross_val = 0\n",
    "max_f1_score = 0\n",
    "cv = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# implement regularization\n",
    "for coef in coefs:\n",
    "    LogReg = LogisticRegression(C=coef, solver='lbfgs', multi_class='multinomial', max_iter=5000)\n",
    "    LogReg.fit(train_X, train_y)\n",
    "    # implement cross-validation and get a f1_score\n",
    "    cross_val = cross_val_score(LogReg, train_X, train_y, cv=cv, scoring='f1_macro')\n",
    "    cross_val = np.mean(cross_val)\n",
    "    #cur_f1_score = f1_score(train_y, LogReg.predict(train_X), average='macro', labels=np.unique(LogReg.predict(train_X)))\n",
    "\n",
    "    # get a minimum cross-validation error by f1_score\n",
    "    if cross_val > max_cross_val:\n",
    "        opt_LogReg = LogReg\n",
    "        max_cross_val = cross_val\n",
    "    print(\"Maximum F1 Score : {}\".format(max_cross_val))\n",
    "    \n",
    "# print validation error for my model \n",
    "max_f1_score = f1_score(train_y, opt_LogReg.predict(train_X), average='macro', labels=np.unique(opt_LogReg.predict(train_X)))\n",
    "print(\"My LogisticRegression's f1 score : {}\".format(max_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Train and validate your <b>decision tree classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 Score : 0.03731014381813393\n",
      "Maximum F1 Score : 0.06845157224094292\n",
      "Maximum F1 Score : 0.0983715116029885\n",
      "Maximum F1 Score : 0.1371475688216688\n",
      "Maximum F1 Score : 0.1875844794841601\n",
      "Maximum F1 Score : 0.23353274770020857\n",
      "Maximum F1 Score : 0.2860977264634156\n",
      "Maximum F1 Score : 0.36345499799772046\n",
      "Maximum F1 Score : 0.36345499799772046\n",
      "Maximum F1 Score : 0.3789792150378909\n",
      "Maximum F1 Score : 0.40364793400472465\n",
      "Maximum F1 Score : 0.40364793400472465\n",
      "Maximum F1 Score : 0.40364793400472465\n",
      "Maximum F1 Score : 0.40364793400472465\n",
      "My DecisionTree's f1 score : 0.847004413416117\n"
     ]
    }
   ],
   "source": [
    "# Training your decision tree classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#define variables\n",
    "opt_DecisionTree = DecisionTreeClassifier()\n",
    "max_cross_val = 0\n",
    "max_f1_score = 0\n",
    "cv = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# implement regularization\n",
    "for depth in range(1,15):\n",
    "    DecisionTree = DecisionTreeClassifier(criterion='entropy', random_state=0, max_depth=depth)\n",
    "    DecisionTree.fit(train_X, train_y)\n",
    "    # implement cross-validation and get a f1_score\n",
    "    cross_val = cross_val_score(DecisionTree, train_X, train_y, cv = cv, scoring='f1_macro')\n",
    "    cross_val = np.mean(cross_val)\n",
    "\n",
    "    # get a minimum cross-validation error by f1_score\n",
    "    if cross_val > max_cross_val:\n",
    "        opt_DecisionTree = DecisionTree\n",
    "        max_cross_val = cross_val\n",
    "    print(\"Maximum F1 Score : {}\".format(max_cross_val))\n",
    "\n",
    "# print validation error for my model \n",
    "max_f1_score = f1_score(train_y, opt_DecisionTree.predict(train_X), average='macro', labels=np.unique(opt_DecisionTree.predict(train_X)))\n",
    "print(\"My DecisionTree's f1 score : {}\".format(max_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Train and validate your <b>random forest classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 Score : 0.1915\n",
      "Maximum F1 Score : 0.2395\n",
      "Maximum F1 Score : 0.259\n",
      "Maximum F1 Score : 0.281\n",
      "Maximum F1 Score : 0.3235\n",
      "Maximum F1 Score : 0.3395\n",
      "Maximum F1 Score : 0.369\n",
      "Maximum F1 Score : 0.41\n",
      "Maximum F1 Score : 0.41\n",
      "Maximum F1 Score : 0.41\n",
      "Maximum F1 Score : 0.42099999999999993\n",
      "Maximum F1 Score : 0.425\n",
      "Maximum F1 Score : 0.425\n",
      "Maximum F1 Score : 0.4385\n",
      "My RandomForests's f1 score : 0.9793182398811902\n"
     ]
    }
   ],
   "source": [
    "# Training your random forest classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#define variables\n",
    "opt_RandomForests = RandomForestClassifier()\n",
    "max_cross_val = 0\n",
    "max_f1_score = 0\n",
    "cv = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# implement regularization\n",
    "for depth in range(1,15):\n",
    "    for estimators in range(1,15):\n",
    "        RandomForest = RandomForestClassifier(bootstrap=True, criterion='entropy', n_estimators=estimators, random_state=0, max_depth=depth)\n",
    "        RandomForest.fit(train_X, train_y)\n",
    "        # implement cross-validation and get a f1_score\n",
    "        cross_val = cross_val_score(RandomForest, train_X, train_y, cv = cv)\n",
    "        cross_val = np.mean(cross_val)\n",
    "        \n",
    "        # get a minimum cross-validation error by f1_score\n",
    "        if cross_val > max_cross_val:\n",
    "            opt_RandomForests = RandomForest\n",
    "            max_cross_val = cross_val\n",
    "    print(\"Maximum F1 Score : {}\".format(max_cross_val))\n",
    "\n",
    "# print validation error for my model \n",
    "max_f1_score = f1_score(train_y, opt_RandomForests.predict(train_X), average='macro', labels=np.unique(opt_RandomForests.predict(train_X)))\n",
    "print(\"My RandomForests's f1 score : {}\".format(max_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Train and validate your <b>support vector machine classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 Score : 0.3036285621056834\n",
      "Maximum F1 Score : 0.3036285621056834\n",
      "Maximum F1 Score : 0.3036285621056834\n",
      "My SVM's f1 score : 0.46767639497150965\n"
     ]
    }
   ],
   "source": [
    "# Training your support vector machine classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "\n",
    "#define variables\n",
    "opt_SVM = SVC()\n",
    "max_cross_val = 0\n",
    "max_f1_score = 0\n",
    "kernels = [\"linear\", \"poly\", \"rbf\"]\n",
    "coefs = [0.001, 0.01, 0.1, 0.0]\n",
    "Cs = [0.01, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "cv = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "# implement regularization\n",
    "for kernel in kernels:\n",
    "    for coef in coefs:\n",
    "        for C in Cs:\n",
    "            SVM = SVC(C=C, cache_size=200, class_weight=None, coef0=coef,\n",
    "            decision_function_shape='ovr', degree=3, gamma='auto', kernel=kernel,\n",
    "            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "            tol=0.001, verbose=False)\n",
    "            SVM.fit(train_X, train_y)\n",
    "            # implement cross-validation and get a f1_score\n",
    "            cross_val = cross_val_score(SVM, train_X, train_y, cv = cv, scoring='f1_macro')\n",
    "            cross_val = np.mean(cross_val)\n",
    "            # get a minimum cross-validation error by f1_score\n",
    "            if cross_val > max_cross_val:\n",
    "                opt_SVM = SVM\n",
    "                max_cross_val = cross_val\n",
    "    print(\"Maximum F1 Score : {}\".format(max_cross_val))\n",
    "\n",
    "# print validation error for my model\n",
    "max_f1_score = f1_score(train_y, opt_SVM.predict(train_X), average='macro', labels=np.unique(opt_SVM.predict(train_X)))\n",
    "print(\"My SVM's f1 score : {}\".format(max_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Option) Other Classifiers.\n",
    "Train and validate other classifiers by your own manner.\n",
    "> <b> If you need, you can import other models only in this cell, only in scikit-learn. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Optimal Model is : Bagging\n",
      "Maximum F1 Score : 0.4388685733857348\n",
      "Current Optimal Model is : Bagging\n",
      "Maximum F1 Score : 0.4388685733857348\n",
      "Current Optimal Model is : Bagging\n",
      "Maximum F1 Score : 0.4388685733857348\n",
      "My model is : Bagging\n",
      "My model's f1 score : 0.9894168251655395\n"
     ]
    }
   ],
   "source": [
    "# If you need additional packages, import your own packages below.\n",
    "# Your Code Here\n",
    "#define variables\n",
    "opt_model = GradientBoostingClassifier()\n",
    "max_cross_val = 0\n",
    "max_f1_score = 0\n",
    "myModel = \"\"\n",
    "learning_rates = [1.0, 0.1, 0.01]\n",
    "cv = KFold(5, shuffle=True, random_state=1)\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for depth in range(1,5):\n",
    "        GradientBoosting = GradientBoostingClassifier(learning_rate=learning_rate, max_depth=depth)\n",
    "        GradientBoosting = GradientBoosting.fit(train_X, train_y)\n",
    "        # implement cross-validation and get a f1_score\n",
    "        cross_val = cross_val_score(GradientBoosting, train_X, train_y, cv = cv, scoring='f1_macro')\n",
    "        cross_val = np.mean(cross_val)\n",
    "        # get a minimum cross-validation error by f1_score\n",
    "        if cross_val > max_cross_val:\n",
    "            opt_model = GradientBoosting\n",
    "            max_cross_val = cross_val\n",
    "            myModel = \"GradientBoosting\"\n",
    "        \n",
    "    Bagging = BaggingClassifier()\n",
    "    Bagging = Bagging.fit(train_X, train_y)\n",
    "    # implement cross-validation and get a f1_score\n",
    "    cross_val = cross_val_score(Bagging, train_X, train_y, cv = cv, scoring='f1_macro')\n",
    "    cross_val = np.mean(cross_val)\n",
    "    # get a minimum cross-validation error by f1_score\n",
    "    if cross_val > max_cross_val:\n",
    "        opt_model = Bagging\n",
    "        max_cross_val = cross_val\n",
    "        myModel = \"Bagging\"\n",
    "    print (\"Current Optimal Model is : {}\".format(myModel))\n",
    "    print(\"Maximum F1 Score : {}\".format(max_cross_val))\n",
    "\n",
    "# print validation error for my model\n",
    "max_f1_score = f1_score(train_y, opt_model.predict(train_X), average='macro', labels=np.unique(opt_model.predict(train_X)))\n",
    "print(\"My model is : {}\".format(myModel))\n",
    "print(\"My model's f1 score : {}\".format(max_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your prediction on the test data.\n",
    "\n",
    "* Select your model and explain it briefly.\n",
    "* You should read <b>\"test.csv\"</b>.\n",
    "* Prerdict your model in array form.\n",
    "* Prediction example <br>\n",
    "[2, 6, 14, 8, $\\cdots$]\n",
    "* We will rank your result by <b>F1 metric(with 'macro' option)</b>.\n",
    "* <b> If you don't submit prediction file or submit it in wrong format, you can't get the point for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'위의 모델들 중 재가 구현한 모델 중 Bagging 모델이 F1 Score 가 가장 높으므로 Bagging 의최적화 된 패러미터를 고른 \\nopt_model 모델을 사용했습니다.모든 모델들을 regularization 및 cross validation 을 사용하여, \\n최적의 모델을 찾았고, 최종 최적모델 들 중에서도 cross validation 을 이용한 f1 score 와 전체 데이터셋에 대한 F1 score 모두 \\n저의 모델이 가장 좋은 성능을 보였습니다.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explain your final model\n",
    "'''위의 모델들 중 재가 구현한 모델 중 Bagging 모델이 F1 Score 가 가장 높으므로 Bagging 의최적화 된 패러미터를 고른 \n",
    "opt_model 모델을 사용했습니다.모든 모델들을 regularization 및 cross validation 을 사용하여, \n",
    "최적의 모델을 찾았고, 최종 최적모델 들 중에서도 cross validation 을 이용한 f1 score 와 전체 데이터셋에 대한 F1 score 모두 \n",
    "저의 모델이 가장 좋은 성능을 보였습니다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset.\n",
    "# Your Code Here\n",
    "test_data = pd.read_csv(\"data/test.csv\", index_col=0)\n",
    "test_values = test_data.reset_index().values\n",
    "real_features = [1,3,5]\n",
    "categorical_features = [0,2,4]\n",
    "test_X = np.asarray(test_values)\n",
    "\n",
    "        \n",
    "# implement OneHotEncoding\n",
    "for val in categorical_features:\n",
    "    feature = test_values[:,val]\n",
    "    feature = oneHot.fit_transform(feature.reshape(-1,1)).toarray()\n",
    "    test_X = np.concatenate((test_X, feature), axis = 1)\n",
    "# end OneHotEncoding\n",
    "\n",
    "# implement delete categorical datas and refine training y data\n",
    "test_X = np.delete(test_X, categorical_features, 1)\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target class\n",
    "# Make variable \"my_answer\", type of array, and fill this array with your class predictions.\n",
    "# Modify file name into your student number and your name.\n",
    "# Your Code Here\n",
    "my_answer = opt_model.predict(test_X)\n",
    "file_name = \"HW2_2013190709_김민상.csv\"\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for saving predicted answers. DO NOT MODIFY.\n",
    "pd.Series(my_answer).to_csv(\"./data/\" + file_name, header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
