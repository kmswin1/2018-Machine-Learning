{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #1 \n",
    "\n",
    "#### Machine Learning in Korea University\n",
    "#### COSE362, Fall 2018 (Prof. Jaewoo Kang)\n",
    "#### Due : 11/6 (TUE) 11:59 PM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, you will learn model selection process among various hyperparameters.\n",
    "* Implementation detail: Anaconda 5.3 with python 3.7\n",
    "* Use given dataset. Please do not change training / validation / test split.\n",
    "* Use numpy, scikit-learn, and matplotlib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression with Feature Selection\n",
    "In this example we will conduct featrue selection process in linear regression model. <br>\n",
    "You will use data in 'LinReg' directory for this example. <br>\n",
    "Please perform the following steps. \n",
    "> 0. Preprocess: Change given dataset into input array for scikit-learn model.\n",
    "> 1. Feture selection : perform greedy feature selection.\n",
    "> 2. Plot: plot validation and train error against number of feature.\n",
    "> 3. Model selection and evaluation: Select best model and perform evaluation on test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-0. Preprocess\n",
    "Load dataset and process it into appropriate array form.\n",
    "* Example <br>\n",
    "> For linear regression problem, the datasets are described onto 'dev_sample.npy', 'dev_label.npy', 'test_sample.npy', 'test_label.npy' in 'LinReg' folder. <br>\n",
    "> Load these datasets onto <b>X_dev, y_dev, X_test, y_test</b>. <br>\n",
    "> You may need to use numpy.load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 2)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load linear regression datasets\n",
    "# Your code here\n",
    "X_dev = np.load('LinReg/dev_sample.npy')\n",
    "y_dev = np.load('LinReg/dev_label.npy')\n",
    "X_test = np.load('LinReg/test_sample.npy')\n",
    "y_test = np.load('LinReg/test_label.npy')\n",
    "# End your code\n",
    "temp = []\n",
    "temp.append(X_dev[:,1])\n",
    "temp.append(X_dev[:,2])\n",
    "temp = np.array(temp)\n",
    "temp.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Feature selection\n",
    "Build linear regression models with different number of features. (1 ~ 100)<br>\n",
    "Please use <b>cross validation</b>, <b>greedy approach</b> for feature selection until choose optimal number of features. <br> \n",
    "\n",
    "* For cross validaton, you need to split your development set into 5-fold. This is implemented into class <b>cv</b>.\n",
    "* Feature selection example : Input with 10 features\n",
    "> Call 10 features as #1, #2, #3, ..., #10 <br>\n",
    "> First build 10 models with only one feature. \n",
    "> Compare model with #1, model with #2, ... , model with #10 <br>\n",
    "> Choose feature of the best model. (for example, #1 is the best) <br>\n",
    "> Build model with 2 features. (#1, #2), (#1, #3), ..., (#1, #10). <br>\n",
    "> Then, add feature with the best performance. <br>\n",
    "> And so on...\n",
    "\n",
    "<b>For the next step, please save validation and train error of the best model for each number of selected features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# of selected feature(s) : 1\n",
      "Selected feature of this iteration : 1\n",
      "==================================================\n",
      "# of selected feature(s) : 2\n",
      "Selected feature of this iteration : 3\n",
      "==================================================\n",
      "# of selected feature(s) : 3\n",
      "Selected feature of this iteration : 45\n",
      "==================================================\n",
      "# of selected feature(s) : 4\n",
      "Selected feature of this iteration : 109\n",
      "==================================================\n",
      "# of selected feature(s) : 5\n",
      "Selected feature of this iteration : 53\n",
      "==================================================\n",
      "# of selected feature(s) : 6\n",
      "Selected feature of this iteration : 44\n",
      "==================================================\n",
      "# of selected feature(s) : 7\n",
      "Selected feature of this iteration : 43\n",
      "==================================================\n",
      "# of selected feature(s) : 8\n",
      "Selected feature of this iteration : 116\n",
      "==================================================\n",
      "# of selected feature(s) : 9\n",
      "Selected feature of this iteration : 95\n",
      "==================================================\n",
      "# of selected feature(s) : 10\n",
      "Selected feature of this iteration : 21\n",
      "==================================================\n",
      "# of selected feature(s) : 11\n",
      "Selected feature of this iteration : 77\n",
      "==================================================\n",
      "# of selected feature(s) : 12\n",
      "Selected feature of this iteration : 80\n",
      "==================================================\n",
      "# of selected feature(s) : 13\n",
      "Selected feature of this iteration : 97\n",
      "==================================================\n",
      "# of selected feature(s) : 14\n",
      "Selected feature of this iteration : 26\n",
      "==================================================\n",
      "# of selected feature(s) : 15\n",
      "Selected feature of this iteration : 24\n",
      "==================================================\n",
      "# of selected feature(s) : 16\n",
      "Selected feature of this iteration : 36\n",
      "==================================================\n",
      "# of selected feature(s) : 17\n",
      "Selected feature of this iteration : 40\n",
      "==================================================\n",
      "# of selected feature(s) : 18\n",
      "Selected feature of this iteration : 117\n",
      "==================================================\n",
      "# of selected feature(s) : 19\n",
      "Selected feature of this iteration : 92\n",
      "==================================================\n",
      "# of selected feature(s) : 20\n",
      "Selected feature of this iteration : 84\n",
      "==================================================\n",
      "# of selected feature(s) : 21\n",
      "Selected feature of this iteration : 110\n",
      "==================================================\n",
      "# of selected feature(s) : 22\n",
      "Selected feature of this iteration : 98\n",
      "==================================================\n",
      "# of selected feature(s) : 23\n",
      "Selected feature of this iteration : 15\n",
      "==================================================\n",
      "# of selected feature(s) : 24\n",
      "Selected feature of this iteration : 6\n",
      "==================================================\n",
      "# of selected feature(s) : 25\n",
      "Selected feature of this iteration : 118\n",
      "==================================================\n",
      "# of selected feature(s) : 26\n",
      "Selected feature of this iteration : 85\n",
      "==================================================\n",
      "# of selected feature(s) : 27\n",
      "Selected feature of this iteration : 113\n",
      "==================================================\n",
      "# of selected feature(s) : 28\n",
      "Selected feature of this iteration : 0\n",
      "==================================================\n",
      "# of selected feature(s) : 29\n",
      "Selected feature of this iteration : 69\n",
      "==================================================\n",
      "# of selected feature(s) : 30\n",
      "Selected feature of this iteration : 99\n",
      "==================================================\n",
      "# of selected feature(s) : 31\n",
      "Selected feature of this iteration : 104\n",
      "==================================================\n",
      "# of selected feature(s) : 32\n",
      "Selected feature of this iteration : 31\n",
      "==================================================\n",
      "# of selected feature(s) : 33\n",
      "Selected feature of this iteration : 62\n",
      "==================================================\n",
      "# of selected feature(s) : 34\n",
      "Selected feature of this iteration : 121\n",
      "==================================================\n",
      "# of selected feature(s) : 35\n",
      "Selected feature of this iteration : 0\n",
      "==================================================\n",
      "# of selected feature(s) : 36\n",
      "Selected feature of this iteration : 35\n",
      "==================================================\n",
      "# of selected feature(s) : 37\n",
      "Selected feature of this iteration : 0\n",
      "==================================================\n",
      "# of selected feature(s) : 38\n",
      "Selected feature of this iteration : 120\n",
      "==================================================\n",
      "# of selected feature(s) : 39\n",
      "Selected feature of this iteration : 17\n",
      "==================================================\n",
      "# of selected feature(s) : 40\n",
      "Selected feature of this iteration : 42\n",
      "==================================================\n",
      "# of selected feature(s) : 41\n",
      "Selected feature of this iteration : 25\n",
      "==================================================\n",
      "# of selected feature(s) : 42\n",
      "Selected feature of this iteration : 108\n",
      "==================================================\n",
      "# of selected feature(s) : 43\n",
      "Selected feature of this iteration : 51\n",
      "==================================================\n",
      "# of selected feature(s) : 44\n",
      "Selected feature of this iteration : 14\n",
      "==================================================\n",
      "# of selected feature(s) : 45\n",
      "Selected feature of this iteration : 2\n",
      "==================================================\n",
      "# of selected feature(s) : 46\n",
      "Selected feature of this iteration : 22\n",
      "==================================================\n",
      "# of selected feature(s) : 47\n",
      "Selected feature of this iteration : 57\n",
      "==================================================\n",
      "# of selected feature(s) : 48\n",
      "Selected feature of this iteration : 81\n",
      "==================================================\n",
      "# of selected feature(s) : 49\n",
      "Selected feature of this iteration : 65\n",
      "==================================================\n",
      "# of selected feature(s) : 50\n",
      "Selected feature of this iteration : 33\n",
      "==================================================\n",
      "# of selected feature(s) : 51\n",
      "Selected feature of this iteration : 37\n",
      "==================================================\n",
      "# of selected feature(s) : 52\n",
      "Selected feature of this iteration : 30\n",
      "==================================================\n",
      "# of selected feature(s) : 53\n",
      "Selected feature of this iteration : 11\n",
      "==================================================\n",
      "# of selected feature(s) : 54\n",
      "Selected feature of this iteration : 71\n",
      "==================================================\n",
      "# of selected feature(s) : 55\n",
      "Selected feature of this iteration : 18\n",
      "==================================================\n",
      "# of selected feature(s) : 56\n",
      "Selected feature of this iteration : 50\n",
      "==================================================\n",
      "# of selected feature(s) : 57\n",
      "Selected feature of this iteration : 102\n",
      "==================================================\n",
      "# of selected feature(s) : 58\n",
      "Selected feature of this iteration : 66\n",
      "==================================================\n",
      "# of selected feature(s) : 59\n",
      "Selected feature of this iteration : 75\n",
      "==================================================\n",
      "# of selected feature(s) : 60\n",
      "Selected feature of this iteration : 46\n",
      "==================================================\n",
      "# of selected feature(s) : 61\n",
      "Selected feature of this iteration : 49\n",
      "==================================================\n",
      "# of selected feature(s) : 62\n",
      "Selected feature of this iteration : 10\n",
      "==================================================\n",
      "# of selected feature(s) : 63\n",
      "Selected feature of this iteration : 34\n",
      "==================================================\n",
      "# of selected feature(s) : 64\n",
      "Selected feature of this iteration : 100\n",
      "==================================================\n",
      "# of selected feature(s) : 65\n",
      "Selected feature of this iteration : 114\n",
      "==================================================\n",
      "# of selected feature(s) : 66\n",
      "Selected feature of this iteration : 54\n",
      "==================================================\n",
      "# of selected feature(s) : 67\n",
      "Selected feature of this iteration : 39\n",
      "==================================================\n",
      "# of selected feature(s) : 68\n",
      "Selected feature of this iteration : 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# of selected feature(s) : 69\n",
      "Selected feature of this iteration : 4\n",
      "==================================================\n",
      "# of selected feature(s) : 70\n",
      "Selected feature of this iteration : 38\n",
      "==================================================\n",
      "# of selected feature(s) : 71\n",
      "Selected feature of this iteration : 124\n",
      "==================================================\n",
      "# of selected feature(s) : 72\n",
      "Selected feature of this iteration : 5\n",
      "==================================================\n",
      "# of selected feature(s) : 73\n",
      "Selected feature of this iteration : 86\n",
      "==================================================\n",
      "# of selected feature(s) : 74\n",
      "Selected feature of this iteration : 55\n",
      "==================================================\n",
      "# of selected feature(s) : 75\n",
      "Selected feature of this iteration : 16\n",
      "==================================================\n",
      "# of selected feature(s) : 76\n",
      "Selected feature of this iteration : 27\n",
      "==================================================\n",
      "# of selected feature(s) : 77\n",
      "Selected feature of this iteration : 61\n",
      "==================================================\n",
      "# of selected feature(s) : 78\n",
      "Selected feature of this iteration : 32\n",
      "==================================================\n",
      "# of selected feature(s) : 79\n",
      "Selected feature of this iteration : 23\n",
      "==================================================\n",
      "# of selected feature(s) : 80\n",
      "Selected feature of this iteration : 41\n",
      "==================================================\n",
      "# of selected feature(s) : 81\n",
      "Selected feature of this iteration : 87\n",
      "==================================================\n",
      "# of selected feature(s) : 82\n",
      "Selected feature of this iteration : 9\n",
      "==================================================\n",
      "# of selected feature(s) : 83\n",
      "Selected feature of this iteration : 59\n",
      "==================================================\n",
      "# of selected feature(s) : 84\n",
      "Selected feature of this iteration : 60\n",
      "==================================================\n",
      "# of selected feature(s) : 85\n",
      "Selected feature of this iteration : 73\n",
      "==================================================\n",
      "# of selected feature(s) : 86\n",
      "Selected feature of this iteration : 88\n",
      "==================================================\n",
      "# of selected feature(s) : 87\n",
      "Selected feature of this iteration : 72\n",
      "==================================================\n",
      "# of selected feature(s) : 88\n",
      "Selected feature of this iteration : 48\n",
      "==================================================\n",
      "# of selected feature(s) : 89\n",
      "Selected feature of this iteration : 67\n",
      "==================================================\n",
      "# of selected feature(s) : 90\n",
      "Selected feature of this iteration : 119\n",
      "==================================================\n",
      "# of selected feature(s) : 91\n",
      "Selected feature of this iteration : 103\n",
      "==================================================\n",
      "# of selected feature(s) : 92\n",
      "Selected feature of this iteration : 79\n",
      "==================================================\n",
      "# of selected feature(s) : 93\n",
      "Selected feature of this iteration : 64\n",
      "==================================================\n",
      "# of selected feature(s) : 94\n",
      "Selected feature of this iteration : 74\n",
      "==================================================\n",
      "# of selected feature(s) : 95\n",
      "Selected feature of this iteration : 13\n",
      "==================================================\n",
      "# of selected feature(s) : 96\n",
      "Selected feature of this iteration : 20\n",
      "==================================================\n",
      "# of selected feature(s) : 97\n",
      "Selected feature of this iteration : 105\n",
      "==================================================\n",
      "# of selected feature(s) : 98\n",
      "Selected feature of this iteration : 93\n",
      "==================================================\n",
      "# of selected feature(s) : 99\n",
      "Selected feature of this iteration : 91\n",
      "==================================================\n",
      "# of selected feature(s) : 100\n",
      "Selected feature of this iteration : 123\n"
     ]
    }
   ],
   "source": [
    "# Define linear regression function\n",
    "# You may use sklearn.linear_model.LinearRegression\n",
    "# Your code here\n",
    "model = LinearRegression()\n",
    "X_dev_fs = np.array([])\n",
    "# End your code\n",
    "\n",
    "# Basic settings. DO NOT MODIFY\n",
    "selected_feature = []\n",
    "sel_num = 100\n",
    "valid_split = 1/5\n",
    "cv = ShuffleSplit(n_splits=5, test_size=valid_split, random_state=0)\n",
    "\n",
    "selected_train_error = []\n",
    "selected_valid_error = []\n",
    "\n",
    "# For greedy selection\n",
    "for sel in range(sel_num) :\n",
    "    min_train_error = +1000\n",
    "    min_valid_error = +1000\n",
    "    min_feature = 0\n",
    "    \n",
    "    # For each feature\n",
    "    for i in range(X_dev.shape[1]) :\n",
    "        train_error_ith = []\n",
    "        valid_error_ith = []\n",
    "        \n",
    "        # Select feature greedy\n",
    "        # Hint : There should be no duplicated feature in selected_feature\n",
    "        # Your code here\n",
    "        temp = []\n",
    "        for feature in selected_feature:\n",
    "            temp.append(X_dev[:,feature])\n",
    "        if i not in selected_feature:\n",
    "            temp.append(X_dev[:,i])\n",
    "            temp = np.array(temp)\n",
    "            X_dev_fs = temp\n",
    "            X_dev_fs = X_dev_fs.T\n",
    "        # End your code\n",
    "        \n",
    "        # For cross validation\n",
    "        for train_index, test_index in cv.split(X_dev) :\n",
    "            X_train, X_valid = X_dev_fs[train_index], X_dev_fs[test_index]\n",
    "            y_train, y_valid = y_dev[train_index], y_dev[test_index]\n",
    "            # Derive training error, validation error\n",
    "            # You may use sklearn.metrics.mean_squared_error, model.fit(), model.predict()\n",
    "            # Your code here\n",
    "            model.fit(X_train, y_train)\n",
    "            train_predict_val = model.predict(X_train)\n",
    "            valid_predict_val = model.predict(X_valid)\n",
    "            train_error = mean_squared_error(train_predict_val, y_train)\n",
    "            valid_error = mean_squared_error(valid_predict_val, y_valid)\n",
    "            train_error_ith.append(train_error)\n",
    "            valid_error_ith.append(valid_error)\n",
    "            # End your code\n",
    "            \n",
    "        # Select best performance feature set on each features\n",
    "        # You should choose the feature which has minimum mean cross validation error\n",
    "        # Your code here\n",
    "        train_mean_error = np.mean(train_error_ith)\n",
    "        valid_mean_error = np.mean(valid_error_ith)\n",
    "        if valid_mean_error < min_valid_error:\n",
    "            min_valid_error = valid_mean_error\n",
    "            min_train_error = train_mean_error\n",
    "            min_feature = i\n",
    "        # End your code\n",
    "    print('='*50)\n",
    "    print(\"# of selected feature(s) : {}\".format(sel+1))\n",
    "    print(\"Selected feature of this iteration : {}\".format(min_feature))\n",
    "    selected_feature.append(min_feature)\n",
    "    selected_train_error.append(min_train_error)\n",
    "    selected_valid_error.append(min_valid_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Plot error\n",
    "Plot train and validation error against number of features.<br>\n",
    "After plotting, <b>analyze the result graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train error plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(np.arange(1,sel_num+1), selected_train_error)\n",
    "plt.title('Training error')\n",
    "plt.legend(['error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation error plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(np.arange(1,sel_num+1), selected_valid_error)\n",
    "plt.title('Validation error')\n",
    "plt.legend(['error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze\n",
    "Write explanation of graph below. <br>\n",
    "Analyze the folloing points.\n",
    "* Trend of each error against number of features\n",
    "* Meaning of gap between vlidation error and train error\n",
    "* Meaning of each region in graph\n",
    "* Others..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-252-cf4d707b6022>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-252-cf4d707b6022>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    1. Training error 는 Feature 를 뽑을때 마다 꾸준히 감소한다. 이것은 수업에서 배운대로, dimension 이 높아지면, 무조건 training error는\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Write description here\n",
    "1. Training error 는 Feature 를 뽑을때 마다 꾸준히 감소한다. 이것은 수업에서 배운대로, dimension 이 높아지면, 무조건 training error는\n",
    "감소하게 된다. \n",
    "2. Validation error 는 꾸준히 늘어나다가 30개이상 쯤부터 다시 증가하는 것을 볼 수 있다.\n",
    "3. 그래프 초반 Training error 와 Validation error 보다 계속 꾸준히 감소하고 있다. 그러나 Training error 와 Validation error 가\n",
    "모두 크므로, high bias 구간이다. 그래프 중간쯤에는, (30개 부근) Training error 는 어느정도 있지만, validation error 가 최소가 되었다. \n",
    "그러나 아직 Training error 가 validation error 보다 높다.\n",
    "그래프 오른쪽에는 validation error 는 다시 증가하고, Training error 는 계속 감소하므로, high variance 구간으로 가고있다. 그러나,\n",
    "그 중간에 Training error 가 validation error 보다 작으면서 Validation error도 여전히 적은 적절한 optimal 한 부분이 있고, \n",
    "그 것을 선택해야 우리의 최선의 모델이 된다.\n",
    "4. training error 가 높은 구간은 애초에 training data set 조차도 잘 맞추지 못하므로 high bias 구간이다. 그리고 계속 감소하지만,\n",
    "좋은 모델인지는 이제 validation error 를 확인해야 한다.\n",
    "5. Validation error 에 대하여 Feature 의 갯수가 늘어날 수록 잘 맞추어 나가지만, 어느순간 training error 는 감소해도,\n",
    "validation 은 증가하는 그 30개 이상 부분은 high variance 구간이라고 할 수 있다. \n",
    "6. Validation error 가 최소인 Feature 들을 그리디하게 추가해서 뽑았으므로, Validation error 는 꾸준히 감소하지만, 어느순간 증가하는 모습을\n",
    "보인다. 그리하여 굳 100개를 뽑을 필요가 없고, 증가하는 순간 break 하는 것이 타당하지 않나? 라는 생각을 처음에 했었지만,\n",
    "training error 도 꾸준하게 감소하는모습을 보이므로, 적절한 모델은 좀 더 지켜봐야 할수도 있겠다는 생각을 했다. \n",
    "greedy 한 모델이 무언가 항상 최적의 솔루션을 주진 않겠지만,\n",
    "그래도 어느정도 모델선택에서 우리가 원하는 learning curve 형태를 그리므로, 괜찮은 알고리즘이라고 생각한다.\n",
    "마지막으로, 나는 Validation error 는 좀 높아지지만, Training error 가 그만큼 낮아지므로, Training error < Validation error\n",
    "이면서, Validation error 도 적당히 작은 77개 부근이 optimal model 이라고 생각한다.\n",
    "그래서 아래에 Model selection 은 선택된 피처들 중 77개를 뽑아서 모델을 만들 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Model selection and evaluation\n",
    "Select the best model and perform a test on test dataset.<br>\n",
    "Print the <b>performance on test set</b> with <b>features of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "# of selected features : 77\n",
      "Selected features : \n",
      "[1, 3, 45, 109, 53, 44, 43, 116, 95, 21, 77, 80, 97, 26, 24, 36, 40, 117, 92, 84, 110, 98, 15, 6, 118, 85, 113, 0, 69, 99, 104, 31, 62, 121, 0, 35, 0, 120, 17, 42, 25, 108, 51, 14, 2, 22, 57, 81, 65, 33, 37, 30, 11, 71, 18, 50, 102, 66, 75, 46, 49, 10, 34, 100, 114, 54, 39, 7, 4, 38, 124, 5, 86, 55, 16, 27, 61]\n",
      "Training error : 5.462161506808589\n",
      "Validation error : 4.730789370353572\n",
      "Test error : 8.413698925303905\n"
     ]
    }
   ],
   "source": [
    "# Select optimal feature set corresponding the minimum cross validation error\n",
    "# Your code here\n",
    "temp = []\n",
    "optimal_selected_feature = []\n",
    "for i in range(77):\n",
    "    temp.append(X_dev[:,selected_feature[i]])\n",
    "    optimal_selected_feature.append(selected_feature[i])\n",
    "\n",
    "temp = np.array(temp)\n",
    "X_dev_fs = temp\n",
    "X_dev_fs = X_dev_fs.T\n",
    "# End your code\n",
    "\n",
    "# Basic settings. DO NOT MODIFY\n",
    "min_train_error = 1000\n",
    "min_valid_error = 1000\n",
    "optimal_param = np.array([])\n",
    "\n",
    "for train_index, test_index in cv.split(X_dev) :\n",
    "    X_train, X_valid = X_dev_fs[train_index], X_dev_fs[test_index]\n",
    "    y_train, y_valid = y_dev[train_index], y_dev[test_index]\n",
    "    \n",
    "    # Derive training error, validation error for each fold\n",
    "    # For each fold, you need to compare error with previous minimum error.\n",
    "    # Your code here\n",
    "    model.fit(X_train, y_train)\n",
    "    predict_train = model.predict(X_train)\n",
    "    predict_valid = model.predict(X_valid)\n",
    "    train_error = mean_squared_error(predict_train, y_train)\n",
    "    valid_error = mean_squared_error(predict_valid, y_valid)\n",
    "    if valid_error < min_valid_error:\n",
    "        min_valid_error = valid_error\n",
    "    if train_error < min_train_error:\n",
    "        min_train_error = train_error\n",
    "    # End your code\n",
    "\n",
    "# Find the best model on each fold\n",
    "# Derive test error with best performance model\n",
    "# Your code here\n",
    "temp2 = []\n",
    "for feature in optimal_selected_feature:\n",
    "    temp2.append(X_test[:,feature])\n",
    "    \n",
    "temp2 = np.array(temp2)\n",
    "X_test = temp2\n",
    "X_test = X_test.T\n",
    "predict_test = model.predict(X_test)\n",
    "test_error = mean_squared_error(predict_test, y_test)\n",
    "# End your code\n",
    "\n",
    "# Drop features of final model\n",
    "print(\"Results\")\n",
    "print(\"# of selected features : {}\".format(len(optimal_selected_feature)))\n",
    "print(\"Selected features : \")\n",
    "print(optimal_selected_feature)\n",
    "\n",
    "# Drop test error and accuracy\n",
    "print(\"Training error : {}\".format(min_train_error))\n",
    "print(\"Validation error : {}\".format(min_valid_error))\n",
    "print(\"Test error : {}\".format(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression with Regularizer\n",
    "\n",
    "In this example you will explore the effect of regularization parameter.<br>\n",
    "You will use <b>'Heart Disease Dataset'</b> in <b>'LogReg'</b> for this example. <br>\n",
    "\n",
    "The goal is to predict the presence of heart disease given attributes of a patient.<br>\n",
    "The presence is integer valued from 0 (no presence) to 4, but you have to only distingush presensence (values 1,2,3,4) from absence (value 0). <br>\n",
    "Each attribute is described below. <br>\n",
    "\n",
    "> 1. age : age in years <br>\n",
    "> 2. sex : sex (1 = male; 0 = female) <br>\n",
    "> 3. cp : chest pain type <br>\n",
    "-- Value 1: typical angina <br>\n",
    "-- Value 2: atypical angina <br>\n",
    "-- Value 3: non-anginal pain <br>\n",
    "-- Value 4: asymptomatic  <br>\n",
    "> 4. trestbps : resting blood pressure (in mm Hg on admission to the hospital)  <br>\n",
    "> 5. chol : serum cholestoral in mg/dl  <br>\n",
    "> 6. fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) <br>\n",
    "> 7. restecg  : resting electrocardiographic results <br>\n",
    "-- Value 0: normal <br>\n",
    "-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) <br>\n",
    "-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria <br>\n",
    "> 8. thalach : maximum heart rate achieved <br>\n",
    "> 9. exang : exercise induced angina (1 = yes; 0 = no) <br>\n",
    "> 10. oldpeak : ST depression induced by exercise relative to rest <br>\n",
    "> 11. slope : the slope of the peak exercise ST segment <br>\n",
    "-- Value 1: upsloping <br>\n",
    "-- Value 2: flat <br>\n",
    "-- Value 3: downsloping  <br>\n",
    "> 12. ca : number of major vessels (0-3) colored by flourosopy  <br>\n",
    "> 13. thal : 3 = normal; 6 = fixed defect; 7 = reversable defect  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-0. Preprocess\n",
    "\n",
    "Firstly, read training, validation and test datasets respectively. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(data_type):\n",
    "    f = open('./LogReg/' + data_type + '.data', 'r')\n",
    "\n",
    "    X, Y = [],[]\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        spl = line.split(',')\n",
    "        x = spl[:-1]\n",
    "        y = int(spl[-1])\n",
    "    \n",
    "        \n",
    "        X.append(list(map(float, x)))\n",
    "        \n",
    "        # Define the variable 'binary_label'.\n",
    "        # Note that labels must be 1 or 0.\n",
    "        # Your code here\n",
    "        if y == 0:\n",
    "            binary_label = 1\n",
    "        else :\n",
    "            binary_label = 0\n",
    "        Y.append(binary_label)  # blank\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X_tr, Y_tr = read_data('train')\n",
    "X_va, Y_va = read_data('valid')\n",
    "X_te, Y_te = read_data('test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Converting to one-hot vector\n",
    "\n",
    "Data preprocessing takes several steps after loading data. <br>\n",
    "1. <b>Normailze</b> numerical values. Normalization is defined as <b><i>normalized_value</i> = (value - mean) / std</b>. <br>\n",
    "   You should calculate mean and standard deviation (std) on <b> train data </b> and normalize train, valid and test data.\n",
    "2. For categorical attributes, <b>build dictionaries</b> of each attribute and convert the categorical values to <b>one-hot vectors</b>. <br>\n",
    "3. Concatenate all the obtained values. <br>\n",
    "\n",
    "If you have done correctly, you will get results that are same format as below: \n",
    "* <b>before</b> : [63.0, 1.0, 1.0, 145.0, 233.0, 1.0, 2.0, 150.0, 0.0, 2.3, 3.0, 0.0, 6.0]\n",
    "* <b>after</b> : [0.11099784710934087, 0, 1, 1, 0, 0, 0, 0.035386000081823056, -0.005256085700922788, 0, 1, 0, 0, 1, 0.0026598418293161848, 1, 0, 0.6659671864819814, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0] <br>\n",
    "(The values in the above example can be different from actual values.)<br>\n",
    "\n",
    "<b>Do not use any library such as sklearn.preprocessing. You can use only Numpy. </b><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n",
    "mean = np.mean(X_tr, axis = 0)\n",
    "std = np.std(X_tr, axis = 0)\n",
    "def normalize(X):\n",
    "    for i in range(len(X)):\n",
    "        X[i][0] = (X[i][0]-mean[0])/std[0]\n",
    "        X[i][3] = (X[i][3]-mean[3])/std[3]\n",
    "        X[i][4] = (X[i][4]-mean[4])/std[4]\n",
    "        X[i][7] = (X[i][7]-mean[7])/std[7]\n",
    "        X[i][9] = (X[i][9]-mean[9])/std[9]\n",
    "    return X\n",
    "\n",
    "def oneHotEncoding(X):\n",
    "    for i in range(len(X)):\n",
    "        if X[i][1] == 0:\n",
    "            X[i][1] = [1,0]\n",
    "        elif X[i][1] == 1:\n",
    "            X[i][1] = [0,1]\n",
    "        if X[i][2] == 1:\n",
    "            X[i][2] = [1,0,0,0]\n",
    "        elif X[i][2] == 2:\n",
    "            X[i][2] = [0,1,0,0]\n",
    "        elif X[i][2] == 3:\n",
    "            X[i][2] = [0,0,1,0]\n",
    "        elif X[i][2] == 4:\n",
    "            X[i][2] = [0,0,0,1]\n",
    "        if X[i][5] == 0:\n",
    "            X[i][5] = [1,0]\n",
    "        elif X[i][5] == 1:\n",
    "            X[i][5] = [0,1]\n",
    "        if X[i][6] == 0:\n",
    "            X[i][6] = [1,0,0]\n",
    "        elif X[i][6] == 1:\n",
    "            X[i][6] = [0,1,0]\n",
    "        elif X[i][6] == 2:\n",
    "            X[i][6] = [0,0,1]\n",
    "        if X[i][8] == 0:\n",
    "            X[i][8] = [1,0]\n",
    "        elif X[i][8] == 1:\n",
    "            X[i][8] = [0,1]\n",
    "        if X[i][10] == 1:\n",
    "            X[i][10] = [1,0,0]\n",
    "        elif X[i][10] == 2:\n",
    "            X[i][10] = [0,1,0]\n",
    "        elif X[i][10] == 3:\n",
    "            X[i][10] = [0,0,1]\n",
    "        if X[i][11] == 0:\n",
    "            X[i][11] = [1,0,0,0]\n",
    "        elif X[i][11] == 1:\n",
    "            X[i][11] = [0,1,0,0]\n",
    "        elif X[i][11] == 2:\n",
    "            X[i][11] = [0,0,1,0]\n",
    "        elif X[i][11] == 3:\n",
    "            X[i][11] = [0,0,0,1]\n",
    "        if X[i][12] == 3:\n",
    "            X[i][12] = [1,0,0]\n",
    "        elif X[i][12] == 6:\n",
    "            X[i][12] = [0,1,0]\n",
    "        elif X[i][12] == 7:\n",
    "            X[i][12] = [0,0,1]\n",
    "        temp = []\n",
    "        for j in range(13):\n",
    "            if j == 1 or j == 2 or j == 5 or j == 6 or j == 8 or j == 10 or j == 11 or j == 12:\n",
    "                for k in X[i][j]:\n",
    "                    temp.append(X[i][j][k])\n",
    "            else:\n",
    "                temp.append(X[i][j])\n",
    "        X[i] = temp\n",
    "    return X\n",
    "\n",
    "X_tr = normalize(X_tr)\n",
    "X_tr = oneHotEncoding(X_tr)\n",
    "X_va = normalize(X_va)\n",
    "X_va = oneHotEncoding(X_va)\n",
    "X_te = normalize(X_te)\n",
    "X_te = oneHotEncoding(X_te)\n",
    "# End your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Logistic regression model and regularizer\n",
    "Build logistic regression model with l2 regularization utilizing sklearn. <br>\n",
    "Find the optimal coefficient based on <b>cross entropy loss</b> on thet validation set. <br>\n",
    "Try following regularization parameter settings.\n",
    "* Regularization parameters = 0.01, 0.05, 0.1, 0.5, 1, 10, 100 <br>\n",
    "* Note that regluarization parameter for LogisticRegression in sklearn is inverse of true parameter. <br>\n",
    "  (coef = 0.001 for LogisticRegression   =>  $\\lambda$ = 1000 in our course note)\n",
    "* Your model should be <b>LogisticRegression(C=coef, solver='lbfgs', max_iter=500). </b>\n",
    "  <br>  <b>Do not change the model setting except C. </b> \n",
    "  <br> (coef = each regularization parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.024910415674479, 6.732222473301171, 6.732222473301171, 5.854097659936573, 5.854097659936573, 5.854104436185981, 5.854104436185981]\n",
      "[8.925823077105475, 6.985424412280601, 6.5973392887711535, 5.433083918242809, 5.433083918242809, 4.656922655464702, 5.045007778974149]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Please use below function\n",
    "# logreg = LogisticRegression(C=coef, solver='lbfgs', max_iter=500)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "coefs = [0.01, 0.05, 0.1, 0.5, 1, 10, 100]\n",
    "\n",
    "opt_coef = 1\n",
    "\n",
    "\n",
    "# To plot losses on training and validation sets with varied parameter settings, \n",
    "# save them on lists.\n",
    "loss_tr, loss_va = [],[]\n",
    "\n",
    "# Your code here\n",
    "min_valid_error = +1000\n",
    "for coef in coefs:\n",
    "    logreg = LogisticRegression(C=coef, solver='lbfgs', max_iter=500)\n",
    "    logreg.fit(X_tr, Y_tr)\n",
    "    predict_train = logreg.predict(X_tr)\n",
    "    predict_valid = logreg.predict(X_va)\n",
    "    loss_tr.append(log_loss(predict_train, Y_tr))\n",
    "    loss_va.append(log_loss(predict_valid, Y_va))\n",
    "    if log_loss(predict_valid, Y_va) < min_valid_error:\n",
    "        min_valid_error = log_loss(predict_valid, Y_va)\n",
    "        opt_coef = coef\n",
    "# End your code\n",
    "print(loss_tr)\n",
    "print(loss_va)\n",
    "print(opt_coef)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Plot error\n",
    "Plot the train and validation loss against given regularization parameter <b>(not inverse)</b>.<br>\n",
    "<b> Analyze the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do not fix the code!!\n",
    "\n",
    "plt.plot(coefs, loss_tr, coefs, loss_va, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze \n",
    "Write explanation of graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-188-154ca4bc16ba>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-188-154ca4bc16ba>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    위 그래프에서 learning curve 가 나타난다.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "위 그래프에서 learning curve 가 나타난다.\n",
    "validation error 는 coef 값이 증가할 수록 계속 감소하다가, 10 이 넘어가는 순간 다시 증가한다.\n",
    "그 말은, 즉, coef 가 10 일때 까지는 training error 와 validation error 가 모두 높은 high bias 상태이다가, \n",
    "10 일때, optimal point 를 찍고, 다시 증가하면서, training error는 낮은 수준 유지하지만, validation error 는 높은 high variance 상태를\n",
    "가지게 된다고 볼 수 있다. (coef 값이 증가할 수록 dimension은 높아진다. 위 설명에서 coef = 1/lamda 라고 했으므로)\n",
    "나는 위 그래프를 토대로 coef=10 을 best model 로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Model selection and evaluation\n",
    "\n",
    "Drop the performance on test set with the regularization coefficient of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal : 10, Loss : 6.140, Accuracy : 93.86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your code here\n",
    "logreg = LogisticRegression(C=opt_coef, solver='lbfgs', max_iter=500)\n",
    "logreg.fit(X_tr, Y_tr)\n",
    "predict_test = logreg.predict(X_te)\n",
    "test_loss = log_loss(predict_test, Y_te)\n",
    "test_acc = (100-test_loss)/100\n",
    "# End your code\n",
    "\n",
    "\n",
    "#print regularization paramter of final model and drop test loss and accuracy\n",
    "print (\"Optimal : {}, Loss : {:2.3f}, Accuracy : {:3.2f}\".format(opt_coef, test_loss, test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
